{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import datasets\n",
    "\n",
    "from stanza.models.constituency.tree_reader import read_trees\n",
    "from stanza.models.constituency.parse_tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f663fdad194cc4823d4e42d1469dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563a5774d8914fed8b88dd38328588b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/23.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31add15126f4a59955a00664c5616c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6414d455e0fb4b338511d5d5303f6deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f13813ee6441aba5f1ab24fec6fbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057901916def4240a762fc372407139c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e03691b72ba4dee928bcc20fe4e03e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/348 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conll_data = datasets.load_dataset(\"coref-data/conll2012_indiscrim\", \"english_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_noun_phrases(node: Tree):\n",
    "    if node.label == \"NP\" or node.label == \"NML\":\n",
    "        yield node\n",
    "    if not node.is_leaf():\n",
    "        for child in node.children:\n",
    "            yield from get_all_noun_phrases(child)\n",
    "\n",
    "\n",
    "def get_all_noun_phrase_indices(tree):\n",
    "    # map words to indices and get all noun phrases\n",
    "    str_indices = map(str, range(len(tree)))\n",
    "    index_tree = tree.replace_words(str_indices)\n",
    "    return get_all_noun_phrases(index_tree)\n",
    "\n",
    "\n",
    "def get_np_mentions(sent_i, sentence):\n",
    "    tokens = sentence[\"tokens\"]\n",
    "    parse_tree = sentence[\"misc\"][\"parse_tree\"]\n",
    "\n",
    "    if not parse_tree:\n",
    "        return\n",
    "\n",
    "    trees = read_trees(parse_tree)\n",
    "    assert len(trees) == 1\n",
    "    tree: Tree = trees[0]\n",
    "\n",
    "    assert len(tree) == len(tokens)\n",
    "\n",
    "    for np_node in get_all_noun_phrase_indices(tree):\n",
    "        leaves = np_node.leaf_labels()\n",
    "        yield [sent_i, int(leaves[0]), int(leaves[-1])]\n",
    "\n",
    "\n",
    "def add_singletons(example):\n",
    "    sentences = example[\"sentences\"]\n",
    "    coref_chains = example[\"coref_chains\"]\n",
    "\n",
    "    singleton_mentions = []\n",
    "    for sent_i, sentence in enumerate(sentences):\n",
    "        for m in get_np_mentions(sent_i, sentence):\n",
    "            singleton_mentions.append(m)\n",
    "\n",
    "    return {\"singleton_mentions\": singleton_mentions}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce01bb1507d4e92a5a5ddce8043b36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ba62ff9675467795630a20542a36d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35e4aca3bea45efa011aa200328bb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/348 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "singleton_data = conll_data.map(add_singletons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "135246 155558 417580 0.8694249090371438 0.3238804540447339\n",
      "validation\n",
      "16427 19155 51924 0.8575828765335421 0.31636622756336186\n",
      "test\n",
      "16850 19764 53633 0.8525602104837078 0.31417224470009136\n"
     ]
    }
   ],
   "source": [
    "# calculate precision and recall\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    recalled = 0\n",
    "    total_coref = 0\n",
    "    total_singleton = 0\n",
    "\n",
    "    for example in singleton_data[split]:\n",
    "        coref_chains = example[\"coref_chains\"]\n",
    "        singleton_mentions = example[\"singleton_mentions\"]\n",
    "\n",
    "        coref_mentions = set()\n",
    "        for c in coref_chains:\n",
    "            for m in c:\n",
    "                coref_mentions.add(tuple(m))\n",
    "\n",
    "        singleton_mentions = set([tuple(m) for m in singleton_mentions])\n",
    "\n",
    "        total_coref += len(coref_mentions)\n",
    "        total_singleton += len(singleton_mentions)\n",
    "\n",
    "        recalled += len(singleton_mentions.intersection(coref_mentions))\n",
    "        \n",
    "    print(split)\n",
    "    print(recalled, total_coref, total_singleton, float(recalled) / total_coref, float(recalled) / total_singleton)\n",
    "    # what percent of coref are in singleton? what percent of singleton are in coref?\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate singleton mentions using parse\n",
    "\n",
    "# All noun phrases with distinct headwords are extracted from previously treebanked data\n",
    "# Whenever head-sharing NPs are nested, the largest logical span is used in co-reference (see 2.4.1).\n",
    "## Head-sharing NPs are two (or more) extracted entities, the shorter one(s) contained within the span of the longer,\n",
    "## sharing the same content word as their headword.\n",
    "## In such cases, the longest logical span should be used in co-reference with other mentions. \n",
    "\n",
    "# Possessive proper nouns (Fred's) are extracted from the treebanked data;\n",
    "# however, possessive pronouns (his) must be manually extracted by the annotator and added to the list of mentions\n",
    "\n",
    "# Proper noun PreMods can be co-referenced to existing noun phrases and/or other proper PreMods,\n",
    "# and should be manually extracted by the annotator and added to the list of mentions.\n",
    "# Non-proper and adjectival premodifiers are not eligible for co-reference (see 2.3).\n",
    "## Premodifiers must be proper nouns\n",
    "## Pre-modifying dates and monetary amounts are also eligible for co-reference\n",
    "## Acronymic premodifiers should be co-referenced unless they refer to nationality\n",
    "\n",
    "# Only the single-word head of the verb phrase is included in the span,\n",
    "# even in cases where the entire verb phrase is the logical co-referent.\n",
    "\n",
    "# Appositives: only the whole span is linked for IDENT\n",
    "\n",
    "# Partitives: all and both can corefer in nesting\n",
    "\n",
    "# in, at, to, from cannot be metonyms\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
