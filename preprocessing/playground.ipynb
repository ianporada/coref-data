{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import datasets\n",
    "from stanza.utils.conll import FIELD_TO_IDX, CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 2.82k/2.82k [00:00<00:00, 7.87MB/s]\n",
      "Downloading data: 100%|██████████| 109k/109k [00:00<00:00, 297kB/s]\n",
      "Generating test split: 100%|██████████| 273/273 [00:00<00:00, 27495.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "d = datasets.load_dataset(\"coref-data/davis_wsc_indiscrim\", \"wsc273\")\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anne gave birth to a daughter last month. She is a very charming baby.\n",
      "[[[0, 0, 0]], [[0, 4, 5], [1, 0, 0]]]\n",
      "[['Anne', 'gave', 'birth', 'to', 'a', 'daughter', 'last', 'month', '.'], ['She', 'is', 'a', 'very', 'charming', 'baby', '.']]\n",
      "-----new chain-----\n",
      "Anne\n",
      "-----new chain-----\n",
      "a daughter\n",
      "She\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# a = d.filter(lambda x: \"police\" in x[\"text\"])\n",
    "ex = d[\"test\"].to_list()[i]\n",
    "print(ex[\"text\"])\n",
    "print(ex[\"coref_chains\"])\n",
    "print([[t[\"text\"] for t in s[\"tokens\"]] for s in ex[\"sentences\"]])\n",
    "for chain in ex[\"coref_chains\"]:\n",
    "    print(\"-----new chain-----\")\n",
    "    for sent, start, end in chain:\n",
    "        toks = ex[\"sentences\"][sent][\"tokens\"][start:end+1]\n",
    "        print(\" \".join([t[\"text\"] for t in toks]))\n",
    "i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 1.61k/1.61k [00:00<00:00, 4.74MB/s]\n",
      "Downloading data: 100%|██████████| 64.2k/64.2k [00:00<00:00, 282kB/s]\n",
      "Generating test split: 100%|██████████| 60/60 [00:00<00:00, 11766.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"coref-data/davis_pdp_indiscrim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataset[\"test\"][\"text\"][0]\n",
    "sentences = dataset[\"test\"][\"sentences\"][0]\n",
    "coref_chains = dataset[\"test\"][\"coref_chains\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men had the right to keep their sons working for them until they were 21 years of age.\n",
      "[[[0, 0, 0]], [[0, 7, 7], [0, 12, 12]]]\n",
      "[['Men', 'had', 'the', 'right', 'to', 'keep', 'their', 'sons', 'working', 'for', 'them', 'until', 'they', 'were', '21', 'years', 'of', 'age', '.']]\n",
      "-----new chain-----\n",
      "Men\n",
      "-----new chain-----\n",
      "sons\n",
      "they\n"
     ]
    }
   ],
   "source": [
    "id = 23\n",
    "text = dataset[\"test\"][\"text\"][id]\n",
    "sentences = dataset[\"test\"][\"sentences\"][id]\n",
    "coref_chains = dataset[\"test\"][\"coref_chains\"][id]\n",
    "\n",
    "print(text)\n",
    "print(coref_chains)\n",
    "print([[t[\"text\"] for t in s[\"tokens\"]] for s in sentences])\n",
    "for chain in coref_chains:\n",
    "    print(\"-----new chain-----\")\n",
    "    for sent, start, end in chain:\n",
    "        toks = sentences[sent][\"tokens\"][start:end+1]\n",
    "        print(\" \".join([t[\"text\"] for t in toks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "t = \"Then Dad figured out how much the man owed the store; to that he added the man's board-bill at the cook-shanty. He subtracted that amount from the man's wages, and made out his check\"\n",
    "o = \"the man\"\n",
    "option_starts = [m.start() for m in re.finditer(o, t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 71, 143]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the man', 'the man', 'the man']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(option_starts)\n",
    "[t[s:s+len(o)] for s in option_starts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find about coref_data types\n",
    "etypes = set()\n",
    "spans = set()\n",
    "for lang_ds in corefud_datasets:\n",
    "    for ds in lang_ds.values():\n",
    "        for coref_entities in ds[\"coref_entities\"]:\n",
    "            for entity in coref_entities:\n",
    "                for mention in entity:\n",
    "                        spans.add(mention[\"span\"])\n",
    "                        for x in mention[\"other\"].split(\",\"):\n",
    "                            etypes.add(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
