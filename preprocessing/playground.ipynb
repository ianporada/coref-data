{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "2024-01-26 23:26:20 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json: 370kB [00:00, 102MB/s]                     \n",
      "2024-01-26 23:26:20 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor | Package                |\n",
      "--------------------------------------\n",
      "| tokenize  | combined               |\n",
      "| mwt       | combined               |\n",
      "| pos       | combined_electra-large |\n",
      "| lemma     | combined_charlm        |\n",
      "| depparse  | combined_electra-large |\n",
      "======================================\n",
      "\n",
      "2024-01-26 23:26:20 INFO: Using device: cpu\n",
      "2024-01-26 23:26:20 INFO: Loading: tokenize\n",
      "2024-01-26 23:26:20 INFO: Loading: mwt\n",
      "2024-01-26 23:26:20 INFO: Loading: pos\n",
      "config.json: 100%|██████████| 668/668 [00:00<00:00, 8.57MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.34G/1.34G [00:48<00:00, 27.9MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 27.0/27.0 [00:00<00:00, 194kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 20.6MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 38.0MB/s]\n",
      "2024-01-26 23:27:12 INFO: Loading: lemma\n",
      "2024-01-26 23:27:12 INFO: Loading: depparse\n",
      "2024-01-26 23:27:12 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "from transformers import AutoModel\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse', package=\"default_accurate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Grandma had set a place for Mary; and once Mrs. Wyman was seated, she pulled her, protesting, to it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'id': 1,\n",
       "   'text': 'Grandma',\n",
       "   'lemma': 'Grandma',\n",
       "   'upos': 'PROPN',\n",
       "   'xpos': 'NNP',\n",
       "   'feats': 'Number=Sing',\n",
       "   'head': 3,\n",
       "   'deprel': 'nsubj',\n",
       "   'start_char': 0,\n",
       "   'end_char': 7},\n",
       "  {'id': 2,\n",
       "   'text': 'had',\n",
       "   'lemma': 'have',\n",
       "   'upos': 'AUX',\n",
       "   'xpos': 'VBD',\n",
       "   'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
       "   'head': 3,\n",
       "   'deprel': 'aux',\n",
       "   'start_char': 8,\n",
       "   'end_char': 11},\n",
       "  {'id': 3,\n",
       "   'text': 'set',\n",
       "   'lemma': 'set',\n",
       "   'upos': 'VERB',\n",
       "   'xpos': 'VBN',\n",
       "   'feats': 'Tense=Past|VerbForm=Part',\n",
       "   'head': 0,\n",
       "   'deprel': 'root',\n",
       "   'start_char': 12,\n",
       "   'end_char': 15},\n",
       "  {'id': 4,\n",
       "   'text': 'a',\n",
       "   'lemma': 'a',\n",
       "   'upos': 'DET',\n",
       "   'xpos': 'DT',\n",
       "   'feats': 'Definite=Ind|PronType=Art',\n",
       "   'head': 5,\n",
       "   'deprel': 'det',\n",
       "   'start_char': 16,\n",
       "   'end_char': 17},\n",
       "  {'id': 5,\n",
       "   'text': 'place',\n",
       "   'lemma': 'place',\n",
       "   'upos': 'NOUN',\n",
       "   'xpos': 'NN',\n",
       "   'feats': 'Number=Sing',\n",
       "   'head': 3,\n",
       "   'deprel': 'obj',\n",
       "   'start_char': 18,\n",
       "   'end_char': 23},\n",
       "  {'id': 6,\n",
       "   'text': 'for',\n",
       "   'lemma': 'for',\n",
       "   'upos': 'ADP',\n",
       "   'xpos': 'IN',\n",
       "   'head': 7,\n",
       "   'deprel': 'case',\n",
       "   'start_char': 24,\n",
       "   'end_char': 27},\n",
       "  {'id': 7,\n",
       "   'text': 'Mary',\n",
       "   'lemma': 'Mary',\n",
       "   'upos': 'PROPN',\n",
       "   'xpos': 'NNP',\n",
       "   'feats': 'Number=Sing',\n",
       "   'head': 3,\n",
       "   'deprel': 'obl',\n",
       "   'start_char': 28,\n",
       "   'end_char': 32},\n",
       "  {'id': 8,\n",
       "   'text': ';',\n",
       "   'lemma': ';',\n",
       "   'upos': 'PUNCT',\n",
       "   'xpos': ',',\n",
       "   'head': 3,\n",
       "   'deprel': 'punct',\n",
       "   'start_char': 32,\n",
       "   'end_char': 33},\n",
       "  {'id': 9,\n",
       "   'text': 'and',\n",
       "   'lemma': 'and',\n",
       "   'upos': 'CCONJ',\n",
       "   'xpos': 'CC',\n",
       "   'head': 11,\n",
       "   'deprel': 'cc',\n",
       "   'start_char': 34,\n",
       "   'end_char': 37},\n",
       "  {'id': 10,\n",
       "   'text': 'once',\n",
       "   'lemma': 'once',\n",
       "   'upos': 'ADV',\n",
       "   'xpos': 'RB',\n",
       "   'feats': 'NumType=Mult',\n",
       "   'head': 11,\n",
       "   'deprel': 'advmod',\n",
       "   'start_char': 38,\n",
       "   'end_char': 42},\n",
       "  {'id': 11,\n",
       "   'text': 'Mrs.',\n",
       "   'lemma': 'Mrs.',\n",
       "   'upos': 'PROPN',\n",
       "   'xpos': 'NNP',\n",
       "   'feats': 'Number=Sing',\n",
       "   'head': 3,\n",
       "   'deprel': 'conj',\n",
       "   'start_char': 43,\n",
       "   'end_char': 47}],\n",
       " [{'id': 1,\n",
       "   'text': 'Wyman',\n",
       "   'lemma': 'Wyman',\n",
       "   'upos': 'PROPN',\n",
       "   'xpos': 'NNP',\n",
       "   'feats': 'Number=Sing',\n",
       "   'head': 3,\n",
       "   'deprel': 'nsubj:pass',\n",
       "   'start_char': 48,\n",
       "   'end_char': 53},\n",
       "  {'id': 2,\n",
       "   'text': 'was',\n",
       "   'lemma': 'be',\n",
       "   'upos': 'AUX',\n",
       "   'xpos': 'VBD',\n",
       "   'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
       "   'head': 3,\n",
       "   'deprel': 'aux:pass',\n",
       "   'start_char': 54,\n",
       "   'end_char': 57},\n",
       "  {'id': 3,\n",
       "   'text': 'seated',\n",
       "   'lemma': 'seat',\n",
       "   'upos': 'VERB',\n",
       "   'xpos': 'VBN',\n",
       "   'feats': 'Tense=Past|VerbForm=Part|Voice=Pass',\n",
       "   'head': 0,\n",
       "   'deprel': 'root',\n",
       "   'start_char': 58,\n",
       "   'end_char': 64},\n",
       "  {'id': 4,\n",
       "   'text': ',',\n",
       "   'lemma': ',',\n",
       "   'upos': 'PUNCT',\n",
       "   'xpos': ',',\n",
       "   'head': 6,\n",
       "   'deprel': 'punct',\n",
       "   'start_char': 64,\n",
       "   'end_char': 65},\n",
       "  {'id': 5,\n",
       "   'text': 'she',\n",
       "   'lemma': 'she',\n",
       "   'upos': 'PRON',\n",
       "   'xpos': 'PRP',\n",
       "   'feats': 'Case=Nom|Gender=Fem|Number=Sing|Person=3|PronType=Prs',\n",
       "   'head': 6,\n",
       "   'deprel': 'nsubj',\n",
       "   'start_char': 66,\n",
       "   'end_char': 69},\n",
       "  {'id': 6,\n",
       "   'text': 'pulled',\n",
       "   'lemma': 'pull',\n",
       "   'upos': 'VERB',\n",
       "   'xpos': 'VBD',\n",
       "   'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
       "   'head': 3,\n",
       "   'deprel': 'parataxis',\n",
       "   'start_char': 70,\n",
       "   'end_char': 76},\n",
       "  {'id': 7,\n",
       "   'text': 'her',\n",
       "   'lemma': 'her',\n",
       "   'upos': 'PRON',\n",
       "   'xpos': 'PRP',\n",
       "   'feats': 'Case=Acc|Gender=Fem|Number=Sing|Person=3|PronType=Prs',\n",
       "   'head': 6,\n",
       "   'deprel': 'obj',\n",
       "   'start_char': 77,\n",
       "   'end_char': 80},\n",
       "  {'id': 8,\n",
       "   'text': ',',\n",
       "   'lemma': ',',\n",
       "   'upos': 'PUNCT',\n",
       "   'xpos': ',',\n",
       "   'head': 9,\n",
       "   'deprel': 'punct',\n",
       "   'start_char': 80,\n",
       "   'end_char': 81},\n",
       "  {'id': 9,\n",
       "   'text': 'protesting',\n",
       "   'lemma': 'protest',\n",
       "   'upos': 'VERB',\n",
       "   'xpos': 'VBG',\n",
       "   'feats': 'VerbForm=Ger',\n",
       "   'head': 6,\n",
       "   'deprel': 'advcl',\n",
       "   'start_char': 82,\n",
       "   'end_char': 92},\n",
       "  {'id': 10,\n",
       "   'text': ',',\n",
       "   'lemma': ',',\n",
       "   'upos': 'PUNCT',\n",
       "   'xpos': ',',\n",
       "   'head': 12,\n",
       "   'deprel': 'punct',\n",
       "   'start_char': 92,\n",
       "   'end_char': 93},\n",
       "  {'id': 11,\n",
       "   'text': 'to',\n",
       "   'lemma': 'to',\n",
       "   'upos': 'ADP',\n",
       "   'xpos': 'IN',\n",
       "   'head': 12,\n",
       "   'deprel': 'case',\n",
       "   'start_char': 94,\n",
       "   'end_char': 96},\n",
       "  {'id': 12,\n",
       "   'text': 'it',\n",
       "   'lemma': 'it',\n",
       "   'upos': 'PRON',\n",
       "   'xpos': 'PRP',\n",
       "   'feats': 'Case=Acc|Gender=Neut|Number=Sing|Person=3|PronType=Prs',\n",
       "   'head': 6,\n",
       "   'deprel': 'obl',\n",
       "   'start_char': 97,\n",
       "   'end_char': 99},\n",
       "  {'id': 13,\n",
       "   'text': '.',\n",
       "   'lemma': '.',\n",
       "   'upos': 'PUNCT',\n",
       "   'xpos': '.',\n",
       "   'head': 3,\n",
       "   'deprel': 'punct',\n",
       "   'start_char': 99,\n",
       "   'end_char': 100}]]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "d = datasets.load_dataset(\"coref-data/superglue_wsc_raw\", \"wsc.fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 554/554 [00:00<00:00, 130475.85 examples/s]\n",
      "Filter: 100%|██████████| 104/104 [00:00<00:00, 45339.11 examples/s]\n",
      "Filter: 100%|██████████| 146/146 [00:00<00:00, 51171.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "a = d.filter(lambda x: \"Mrs. Wyman\" in x[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Grandma had set a place for Mary; and once Mrs. Wyman was seated, she pulled her, protesting, to it.',\n",
       "  'span1_index': 0,\n",
       "  'span2_index': 13,\n",
       "  'span1_text': 'Grandma',\n",
       "  'span2_text': 'she',\n",
       "  'idx': 65,\n",
       "  'label': -1},\n",
       " {'text': 'Grandma had set a place for Mary; and once Mrs. Wyman was seated, she pulled her, protesting, to it.',\n",
       "  'span1_index': 9,\n",
       "  'span2_index': 13,\n",
       "  'span1_text': 'Mrs. Wyman',\n",
       "  'span2_text': 'she',\n",
       "  'idx': 66,\n",
       "  'label': -1},\n",
       " {'text': 'Grandma had set a place for Mary; and once Mrs. Wyman was seated, she pulled her, protesting, to it.',\n",
       "  'span1_index': 6,\n",
       "  'span2_index': 13,\n",
       "  'span1_text': 'Mary',\n",
       "  'span2_text': 'she',\n",
       "  'idx': 67,\n",
       "  'label': -1}]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"test\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anne gave birth to a daughter last month. She is a very charming baby.\n",
      "[[[0, 0, 0]], [[0, 4, 5], [1, 0, 0]]]\n",
      "[['Anne', 'gave', 'birth', 'to', 'a', 'daughter', 'last', 'month', '.'], ['She', 'is', 'a', 'very', 'charming', 'baby', '.']]\n",
      "-----new chain-----\n",
      "Anne\n",
      "-----new chain-----\n",
      "a daughter\n",
      "She\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# a = d.filter(lambda x: \"police\" in x[\"text\"])\n",
    "ex = d[\"test\"].to_list()[i]\n",
    "print(ex[\"text\"])\n",
    "print(ex[\"coref_chains\"])\n",
    "print([[t[\"text\"] for t in s[\"tokens\"]] for s in ex[\"sentences\"]])\n",
    "for chain in ex[\"coref_chains\"]:\n",
    "    print(\"-----new chain-----\")\n",
    "    for sent, start, end in chain:\n",
    "        toks = ex[\"sentences\"][sent][\"tokens\"][start:end+1]\n",
    "        print(\" \".join([t[\"text\"] for t in toks]))\n",
    "i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 1.61k/1.61k [00:00<00:00, 4.74MB/s]\n",
      "Downloading data: 100%|██████████| 64.2k/64.2k [00:00<00:00, 282kB/s]\n",
      "Generating test split: 100%|██████████| 60/60 [00:00<00:00, 11766.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"coref-data/davis_pdp_indiscrim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataset[\"test\"][\"text\"][0]\n",
    "sentences = dataset[\"test\"][\"sentences\"][0]\n",
    "coref_chains = dataset[\"test\"][\"coref_chains\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men had the right to keep their sons working for them until they were 21 years of age.\n",
      "[[[0, 0, 0]], [[0, 7, 7], [0, 12, 12]]]\n",
      "[['Men', 'had', 'the', 'right', 'to', 'keep', 'their', 'sons', 'working', 'for', 'them', 'until', 'they', 'were', '21', 'years', 'of', 'age', '.']]\n",
      "-----new chain-----\n",
      "Men\n",
      "-----new chain-----\n",
      "sons\n",
      "they\n"
     ]
    }
   ],
   "source": [
    "id = 23\n",
    "text = dataset[\"test\"][\"text\"][id]\n",
    "sentences = dataset[\"test\"][\"sentences\"][id]\n",
    "coref_chains = dataset[\"test\"][\"coref_chains\"][id]\n",
    "\n",
    "print(text)\n",
    "print(coref_chains)\n",
    "print([[t[\"text\"] for t in s[\"tokens\"]] for s in sentences])\n",
    "for chain in coref_chains:\n",
    "    print(\"-----new chain-----\")\n",
    "    for sent, start, end in chain:\n",
    "        toks = sentences[sent][\"tokens\"][start:end+1]\n",
    "        print(\" \".join([t[\"text\"] for t in toks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "t = \"Then Dad figured out how much the man owed the store; to that he added the man's board-bill at the cook-shanty. He subtracted that amount from the man's wages, and made out his check\"\n",
    "o = \"the man\"\n",
    "option_starts = [m.start() for m in re.finditer(o, t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 71, 143]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the man', 'the man', 'the man']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(option_starts)\n",
    "[t[s:s+len(o)] for s in option_starts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find about coref_data types\n",
    "etypes = set()\n",
    "spans = set()\n",
    "for lang_ds in corefud_datasets:\n",
    "    for ds in lang_ds.values():\n",
    "        for coref_entities in ds[\"coref_entities\"]:\n",
    "            for entity in coref_entities:\n",
    "                for mention in entity:\n",
    "                        spans.add(mention[\"span\"])\n",
    "                        for x in mention[\"other\"].split(\",\"):\n",
    "                            etypes.add(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
